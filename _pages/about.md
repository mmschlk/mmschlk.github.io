---
layout: about
title: About
permalink: /
subtitle: <a href='https://www.kiml.ifi.lmu.de/people/employees/muschalik/index.html'>Artificial Intelligence and Machine Learning</a> at LMU Munich.

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  address: >
    <p>Akademiestr.7</p>
    <p>80799 Munich</p>

news: false  # includes a list of news items
latest_posts: true  # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

Hi, I am Maximilian Muschalik, and I am a PhD student at Prof. [Eyke HÃ¼llermeier's](https://www.kiml.ifi.lmu.de/people/professors/huellermeier/index.html) [AIML](https://www.kiml.ifi.lmu.de/people/employees/muschalik/index.html) chair, LMU Munich.
I also like Shapley interactions quite a lot. So I work on them and develop [shapiq](https://github.com/mmschlk/shapiq).

## Research Focus
My research centers on the topic of explainable artificial intelligence (XAI), with a focus on black-box machine learning models.

Currently, I am mainly working on the topic of Shapley-based explanations and extensions of Shapley values to higher-order interactions.
Therein, we are mostly concerned in developing approximation methods to compute Shapley interactions efficiently, as usually the computational complexity of Shapley interactions is infeasible for most real-world applications.
Recently, we have bundled our research and methods into the Python package [shapiq](https://github.com/mmschlk/shapiq).
If you are interested in Shapley interactions, I would be happy to hear from you.
You can also check out our blog post on [Shapley interactions](https://maxmuschalik.com/blog/2024/shapley-interactions/).

Another interesting are of XAI research is the development of methods that can explain the predictions of models in dynamic learning environments.
Specifically, we investigate the challenges of creating accurate and timely explanations for models that must constantly adapt to changes in data streams and learning tasks.
In such dynamic settings, traditional XAI methods may be computationally expensive or unable to provide faithful explanations in a timely manner.

My research is part of the [TRR 318 Constructing Explainability](https://trr318.uni-paderborn.de/projekte/c03).
